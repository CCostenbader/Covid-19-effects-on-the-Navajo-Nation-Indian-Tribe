<<<<<<< HEAD
ggplot(rr, aes(sample = Miles)) + geom_qq()
# TO GET A SUMMARY OF THE DATA SET "MILES"
summary(Miles)
# CONFIRM IF THERE WERE OUTLIERS
# -ANYTHING 1.5 TIMES HIGHER OR LOWER THAN THE
# VALUE OF THE IQR IS AN OUTLIER.
IQR_RIVERS <- IQR(Miles)
IQR_RIVERS
UPPER_OUTLIER <- (IQR_RIVERS * 1.5)
UPPER_OUTLIER
# CONCLUSIONS
# THERE WERE OUTLIERS
# THERE WERE UPPER OUTLIERS ONLY
# THERE WERE NO LOWER OUTLIERS
# BASED ON THE FAT PENCIL TEST,
# THE DATA FRAME DID NOT COME FROM A
# FROM A NORMAL DISTRIBUTION
library(ggplot2)
# LESSON 5 PAGE 7 HANDS-ON
# The built in data set "rivers" has the length
# in miles of 141 major rivers in North America.
# Using the dataset, create a Histogram with suitable
# bin widths, a box plot, and a normal probability
# plot.
# Then answer the following questions:
# -Are there any outliers?
# -Are they high or low outliers?
# -Do these data appear to come from a
# normal distribution?
# TO ANSWER THESE QUESTIONS, COMPLETE THE
# FOLLOWING FUNCTIONS
# ACCESS THIS
library(datasets)
# the rivers data set
rivers
# create a vector of "length in miles"
# out of the 141 elements in the data set "rivers"
# assign the vector to the variable "Miles"
Miles <- c(rivers)
# build a "data.frame" of length in miles
# from the dataset "rivers"
# and assign it to the variable "rr"
rr = data.frame(rivers)
# to create a histogram
d <- ggplot(rr, aes(x = Miles))
d + geom_histogram(binwidth = 141) +
ggtitle("Histogram of Miles") +
xlab("Length in Miles") +
ylab("Number of Rivers")
# create a box plot
d <- ggplot(rr, aes(x ="", y= Miles))
d + geom_boxplot() + xlab("Number of Rivers")
# to create a "Normal Probability Plot"
ggplot(rr, aes(sample = Miles)) + geom_qq()
# TO GET A SUMMARY OF THE DATA SET "MILES"
summary(Miles)
# CONFIRM IF THERE WERE OUTLIERS
# -ANYTHING 1.5 TIMES HIGHER OR LOWER THAN THE
# VALUE OF THE IQR IS AN OUTLIER.
IQR_RIVERS <- IQR(Miles)
IQR_RIVERS
UPPER_OUTLIER <- (IQR_RIVERS * 1.5)
UPPER_OUTLIER
# CONCLUSIONS
# THERE WERE OUTLIERS
# THERE WERE UPPER OUTLIERS ONLY
# THERE WERE NO LOWER OUTLIERS
# BASED ON THE FAT PENCIL TEST,
# THE DATA FRAME DID NOT COME FROM A
# FROM A NORMAL DISTRIBUTION
# LESSON 5 PAGE 7 HANDS-ON
# The built in data set "rivers" has the length
# in miles of 141 major rivers in North America.
# Using the dataset, create a Histogram with suitable
# bin widths, a box plot, and a normal probability
# plot.
# Then answer the following questions:
# -Are there any outliers?
# -Are they high or low outliers?
# -Do these data appear to come from a
# normal distribution?
# TO ANSWER THESE QUESTIONS, COMPLETE THE
# FOLLOWING FUNCTIONS
# ACCESS THIS
library(datasets)
# the rivers data set
rivers
# create a vector of "length in miles"
# out of the 141 elements in the data set "rivers"
# assign the vector to the variable "Miles"
Miles <- c(rivers)
# build a "data.frame" of length in miles
# from the dataset "rivers"
# and assign it to the variable "rr"
rr = data.frame(rivers)
# to create a histogram
d <- ggplot(rr, aes(x = Miles))
d + geom_histogram(binwidth = 141) +
ggtitle("Histogram of Miles") +
xlab("Length in Miles") +
ylab("Number of Rivers")
# create a box plot
d <- ggplot(rr, aes(x ="", y= Miles))
d + geom_boxplot() + xlab("Number of Rivers")
# to create a "Normal Probability Plot"
ggplot(rr, aes(sample = Miles)) + geom_qq()
# TO GET A SUMMARY OF THE DATA SET "MILES"
summary(Miles)
# CONFIRM IF THERE WERE OUTLIERS
# -ANYTHING 1.5 TIMES HIGHER OR LOWER THAN THE
# VALUE OF THE IQR IS AN OUTLIER.
IQR_RIVERS <- IQR(Miles)
=======
>>>>>>> master
IQR_RIVERS
UPPER_OUTLIER <- (IQR_RIVERS * 1.5)
UPPER_OUTLIER
# CONCLUSIONS
# THERE WERE OUTLIERS
# THERE WERE UPPER OUTLIERS ONLY
# THERE WERE NO LOWER OUTLIERS
# BASED ON THE FAT PENCIL TEST,
# THE DATA FRAME DID NOT COME FROM A
# FROM A NORMAL DISTRIBUTION
library(ggplot2)
library(ggplot2)
Snowman_name <- c("Frosty", "Frostette", "Jack Frost", "Jackie Frost", "Coal Eye")
Accessory <- c("Top Hat", "Scarf", "Coal Buttons", "Twig Arms", "Carrot Nose")
Location <- c("South Dakota", "North Dakota", "Colorado", "Minnesota", "Alaska")
Body_Sections <- c(3,4,2,3,2)
Snowmen <- data.frame(Snowman_name, Accessory, Location, Body_Sections)
head(Snowmen)
Snowman_name <- c("Frosty", "Frostette", "Jack Frost", "Jackie Frost", "Coal Eye")
Accessory <- c("Top Hat", "Scarf", "Coal Buttons", "Twig Arms", "Carrot Nose")
Location <- c("South Dakota", "North Dakota", "Colorado", "Minnesota", "Alaska")
Body_Sections <- c(3,4,2,3,2)
Snowmen <- data.frame(Snowman_name, Accessory, Location, Body_Sections)
Snowman_name <- c("Frosty", "Frostette", "Jack Frost", "Jackie Frost", "Coal Eye")
Accessory <- c("Top Hat", "Scarf", "Coal Buttons", "Twig Arms", "Carrot Nose")
Location <- c("South Dakota", "North Dakota", "Colorado", "Minnesota", "Alaska")
Body_Sections <- c(3,4,2,3,2)
Snowmen <- data.frame(Snowman_name, Accessory, Location, Body_Sections)
View(Snowmen)
head(Snowmen)
tail(Snowmen)
Snowmen
Snowmen$Accessory
Snowmen(3,2)
Snowmen(3,2)
Snowmen(3, 2)
Snowmen[3, 2]
Snowmen[3, ]
Snowmen[3, 2]
Snowmen$Gender <- c("Male", "Female", "Male", "Female", "Male")
View(Snowmen)
Snowmen[3, 2]
Name <- c("Bob", "Nancy", "Cyrus", "Jackie")
Age <- c(36, 31, 26, 34)
Dominant_Hand <- c("Right", "Right", "Left", "Right")
friends <- data.frame(Name, Age, Dominant_Hand)
View(friends)
friends
Name <- c("Bob", "Nancy", "Cyrus", "Jackie")
friends$Name
friends$Dominant_Hand
library(dplyr)
library(ggplot2)
library(ggplot2)
library(dplyr)
View(mtcars)
mtcars %>% group_by(mpg, cyl ) %>% summarize(count = n())
morley
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
boxplot(mtcars$mpg ~ mtcars$cyl, data=mtcars)
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
View(mtcars)
View(mtcars)
mtcars
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
# LESSON 6 PAGE 13 HANDS ON
# REQUIREMENTS
# From the mtcars data frame,
# create a box plot of miles per gallon
# (the mpg variable) grouped by the number of cylinders
# in the engine (the cyl variable).
# Do these box plots make sense?
# Also, use the summarize() and group_by()
# functions to compute how many cars have four cylinders,
# how many have six, and how many have eight.
# Prepare a report (using MS Power Point or similar)
# with all of these elements and any code used to
# arrive at the results.
# VIEW LIBRARY ggplot2
library(ggplot2)
# VIEW LIBRARY dplyr
library(dplyr)
# USE THE DATA FRAME mtcars
View(mtcars)
mtcars
# CREATE A BOX PLOT, FOR THE DATA FRAME mtcars SHOWING MILES PER GALLON
# GROUPED BY THE NUMBER OF CYLINDERS IN THE ENGINE
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
mtcars %>% group_by(cyl) %>% summarize(cyl = n())
mtcars %>% group_by(cyl) %>% summarize(count = n())
# LESSON 6 PAGE 13 HANDS ON
# REQUIREMENTS
# From the mtcars data frame,
# create a box plot of miles per gallon
# (the mpg variable) grouped by the number of cylinders
# in the engine (the cyl variable).
# Do these box plots make sense?
# Also, use the summarize() and group_by()
# functions to compute how many cars have four cylinders,
# how many have six, and how many have eight.
# Prepare a report (using MS Power Point or similar)
# with all of these elements and any code used to
# arrive at the results.
# USING LIBRARY ggplot2
library(ggplot2)
# USING LIBRARY dplyr
library(dplyr)
# USING DATA FRAME mtcars
View(mtcars)
# TO SHOW "mtcars" in the CONSOLE
mtcars
# THEN CREATE A BOX PLOT, FOR THE DATA FRAME mtcars SHOWING MILES PER GALLON
# GROUPED BY THE NUMBER OF CYLINDERS IN THE ENGINE (SEE PLOTS PANE)
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
# TO COMPUTE THE NUMBER OF EACH TYPE OF MOTOR TESTED US THIS FORMULA
mtcars %>% group_by(cyl) %>% summarize(count = n())
# LESSON 6 PAGE 13 HANDS ON
# REQUIREMENTS
# From the mtcars data frame,
# create a box plot of miles per gallon
# (the mpg variable) grouped by the number of cylinders
# in the engine (the cyl variable).
# Do these box plots make sense?
# Also, use the summarize() and group_by()
# functions to compute how many cars have four cylinders,
# how many have six, and how many have eight.
# Prepare a report (using MS Power Point or similar)
# with all of these elements and any code used to
# arrive at the results.
# USING LIBRARY ggplot2
library(ggplot2)
# USING LIBRARY dplyr
library(dplyr)
# USING DATA FRAME mtcars
View(mtcars)
# TO SHOW "mtcars" in the CONSOLE
mtcars
# THEN CREATE A BOX PLOT, FOR THE DATA FRAME mtcars SHOWING MILES PER GALLON
# GROUPED BY THE NUMBER OF CYLINDERS IN THE ENGINE (SEE PLOTS PANE)
ggplot(mtcars, aes(x = cyl, y = mpg)) + geom_boxplot(aes(group=cyl))
# TO COMPUTE THE NUMBER OF EACH TYPE OF MOTOR TESTED US THIS FORMULA
mtcars %>% group_by(cyl) %>% summarize(count = n())
iew(EmployeeAttrition)
library(dplyr)
library(ggplot2)
View(EmployeeAttrition)
View(nhtemp)
nhtemp
first25 <- nhtemp[1:25]
last25 <- nhtemp[36:60]
View(LakeHuron)
library(dplyr)
library(ggplot2)
library(dplyr)
View(LakeHuron)
head(LakeHuron)
install.packages("ggplot2")
install.packages("dplyr")
library(dplyr)
detach("package:dplyr", unload = TRUE)
library(ggplot2)
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point()
View(faithful_histogram)
View(faithful)
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point()
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + + geom_smooth(method=lm) + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + geom_smooth(method=lm) + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + geom_smooth(method=lm, se=FALSE) + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
d <- ggplot(faithful, aes(x = eruptions, y = waiting))
d + geom_point() + geom_smooth(method=lm, se=FALSE, color = "goldenrod2") + ggtitle("Old Faithful Eruption vs Waiting Times") +
xlab("Eruption Time (min)") + ylab("Wating Time (min)")
View(USArrests)
d <- ggplot(USArrests, aes(x = UrbanPop, y = Murder))
d + geom_point() + geom_smooth(method=lm, se=FALSE)
View(mtcars)
d <- ggplot(mtcars, aes(x = disp, y = mpg))
d + geom_point() + geom_smooth(method=lm, se=FALSE)
lin_reg <- lm(dist ~ speed, cars)
print(lin_reg)
summary(lin_reg)
library(dplyr)
library(tidyr)
install.packages("tidyr")
library(tidyr)
library(readxl)
babies <- read_excel("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies/babies.xlsx")
View(babies)
library(readxl)
babies2 <- read_excel("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies/babies2.xlsx")
View(babies2)
View(babies2)
View(babies)
View(babies2)
View(babies2)
babies2 <- read.csv("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies/babies2.xlsx", sep="")
View(babies2)
View(babies2)
babies2 <- read.csv("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies/babies2.csv")
View(babies2)
View(babies2)
View(babies2)
babies2$Footprint = " "
library(dplyr)
library(tidyr)
babies2 <- read.csv("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies in R/babies2.xlsx", sep="")
View(babies2)
babies2 <- read.csv("C:/Users/Craig/Dropbox/PERSONAL/SCHOOL/WOZ U/COURSE WORK/DSO104C/LESSON 1/babies in R/babies2.csv")
View(babies2)
babies$Footprint = " "
babies2$Footprint = " "
View(babies2)
wd()
prop.test(x = 15, n = 43,
alternative = "less",
correction=FALSE)
prop.test(x = 15, n = 43, alternative = "less", correction=FALSE)
prop.test(x = 15, n = 43, alternative = "less")
prop.test(x = 15, n = 43, alternative = "less", correction=FALSE)
prop.test(x = 15, n = 43, alternative = "less")
setwd("C:/Users/Craig/Dropbox/SCHOOL/WOZ U/COURSE WORK/DSO110/FINAL GROUP PROJECT/SCHOOL-GROUP-FINAL/Final/FPr2")
# FINAL GROUP PROJECT IN R
# WORKING DIRECTORY MUST BE SET EACH TIME THIS FILE IS
# OPENED.
# FOR EACH INSTANCE OF WORKING WITH DATASET BELOW
# IN ORDER TO IMPORT DATASET CovidDataSet.csv AND
# FOR R TO WORK PROPERTLY.
# IMPORT LIBRARIES
library("dplyr")
library("rcompanion")
library("car")
library("fastR2")
library("IDPmisc")
# IMPORT DATA SET
CovidDataSet <- read.csv("CovidDataSet2.csv")
# SORTING OUT AZ AND NM STATE FIPS CODES
covid2 <- filter(CovidDataSet,
FIPS %in% c(4001, 4003, 4005, 4007, 4009, 4011, 4012, 4013, 4015, 4017, 4019, 4021, 4023, 4025,4027,
35001, 35003, 35005, 35006, 35007, 35009, 35011, 35013, 35015, 35017, 35019, 35021, 35023, 35025, 35027, 35028, 35029, 35031, 35033, 35035, 35037, 35039, 35041, 35045, 35047, 35043, 35049, 35051, 35053, 35055, 35057, 35059, 35061))
# TRIMMING FIELDS FOR DATA SET
covidtest2 <- select(covid2, FIPS, Province_State, Lat, Long_,
Confirmed, Deaths, Active, Incident_Rate,
Case_Fatality_Ratio)
# Recode with Navajo binary
covidtest2$NavajoR <- NA
## Navajo = 1
covidtest2$NavajoR[covidtest2$FIPS== 4001] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 4005] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 4017] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 35031] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 35045] <- 1
Non-Navajo = 0
covidtest2$NavajoR[covidtest2$FIPS== 4003] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4007] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4009] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4011] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4012] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4013] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4015] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4019] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4021] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4023] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4025] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4027] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35001] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35003] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35005] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35006] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35007] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35009] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35011] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35013] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35015] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35017] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35019] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35021] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35023] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35025] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35027] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35028] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35029] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35033] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35035] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35037] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35039] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35041] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35043] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35047] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35049] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35051] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35053] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35055] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35057] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35059] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35061] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 90049] <- 0
covidtest3 <- select(covidtest2, FIPS, Province_State, Lat, Long_,
Confirmed, Deaths, Active, Incident_Rate,
Case_Fatality_Ratio, NavajoR)
### ANOVA for Confirmed Cases
##Assumptions
#Normality
plotNormalHistogram(covidtest3$Confirmed)
covidtest3$ConfirmedLOG <- log(covidtest3$Confirmed)
plotNormalHistogram(covidtest3$ConfirmedLOG)
<<<<<<< HEAD
#Log is Good
# Homogeneity of Variance
bartlett.test(covidtest3$ConfirmedLOG ~ NavajoR, data= covidtest3)
# P-VALUE IS .0001855 < .05 AND IS NOT SIGNIFICANT
# DOES NOT MEET ASSUMPTION FOR HOMOGENEITY OF VARIANCE
# SAMPLE SIZE IS >20 AND MEETS ASSUMPTION
## Welch's One-Way Test
ANOVA <- lm(ConfirmedLOG ~ NavajoR, data=covidtest3)
Anova(ANOVA, Type="II", white.adjust=TRUE)
# Significant difference between two IVs
View(covid2)
## Bonferroni Adj
pairwise.t.test(covidtest3$ConfirmedLOG, covidtest3$NavajoR,
p.adjust="bonferroni", pool.sd = FALSE)
# Significant difference in Confirmed Cases between
# Navajo / Non-Navajo GROUPS
=======
library("dplyr")
library("rcompanion")
library("car")
library("fastR2")
library("IDPmisc")
# IMPORT DATA SET
CovidDataSet <- read.csv("CovidDataSet.csv")
CovidDataSet <- read.csv("~/Desktop/Final/CovidDataSet.csv", stringsAsFactors=TRUE)
View(CovidDataSet)
# IMPORT DATA SET
CovidDataSet <- read.csv("CovidDataSet2.csv")
covid2 <- filter(CovidDataSet,
FIPS %in% c(4001, 4003, 4005, 4007, 4009, 4011, 4012, 4013, 4015, 4017, 4019, 4021, 4023, 4025,4027,
35001, 35003, 35005, 35006, 35007, 35009, 35011, 35013, 35015, 35017, 35019, 35021, 35023, 35025, 35027, 35028, 35029, 35031, 35033, 35035, 35037, 35039, 35041, 35045, 35047, 35043, 35049, 35051, 35053, 35055, 35057, 35059, 35061))
covidtest2 <- select(covid2, FIPS, Province_State, Lat, Long_,
Confirmed, Deaths, Active, Incident_Rate,
Case_Fatality_Ratio)
covidtest2$NavajoR <- NA
covidtest2$NavajoR[covidtest2$FIPS== 4001] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 4005] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 4017] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 35031] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 35045] <- 1
covidtest2$NavajoR[covidtest2$FIPS== 4003] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4007] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4009] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4011] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4012] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4013] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4015] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4019] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4021] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4023] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4025] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 4027] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35001] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35003] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35005] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35006] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35007] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35009] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35011] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35013] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35015] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35017] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35019] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35021] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35023] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35025] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35027] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35028] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35029] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35033] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35035] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35037] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35039] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35041] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35043] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35047] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35049] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35051] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35053] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35055] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35057] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35059] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 35061] <- 0
covidtest2$NavajoR[covidtest2$FIPS== 90049] <- 0
covidtest3 <- select(covidtest2, FIPS, Province_State, Lat, Long_,
Confirmed, Deaths, Active, Incident_Rate,
Case_Fatality_Ratio, NavajoR)
#Normality
plotNormalHistogram(covidtest3$Confirmed)
covidtest3$ConfirmedLOG <- log(covidtest3$Confirmed)
plotNormalHistogram(covidtest3$ConfirmedLOG)
# Homogeneity of Variance
bartlett.test(covidtest3$ConfirmedLOG ~ NavajoR, data= covidtest3)
## Welch's One-Way Test
ANOVA <- lm(ConfirmedLOG ~ NavajoR, data=covidtest3)
Anova(ANOVA, Type="II", white.adjust=TRUE)
## Bonferroni Adj
pairwise.t.test(covidtest3$ConfirmedLOG, covidtest3$NavajoR,
p.adjust="bonferroni", pool.sd = FALSE)
>>>>>>> master
# Means & conclusions
ConfirmedMeans <- covidtest3 %>% group_by(NavajoR) %>%
summarize(Mean = mean(Confirmed))
View(ConfirmedMeans)
<<<<<<< HEAD
View(CovidDataSet)
View(CovidDataSet)
covidtest3$ConfirmedSQRT <-SQRT(covidtest3$Confirmed)
covidtest3$ConfirmedSQRT <- sqrt(covidtest3$Confirmed)
View(covidtest3)
plotNormalHistogram((covidtest3$ConfirmedSQRT))
plotNormalHistogram(covidtest3$Confirmed)
covidtest3$ConfirmedLOG <- log(covidtest3$Confirmed)
plotNormalHistogram(covidtest3$ConfirmedLOG)
fligner.test(covidtest3$ConfirmedLOG ~ NajajoR, data= covidtest3)
fligner.test(covidtest3$ConfirmedLOG ~ NavajoR, data= covidtest3)
# Welch's One-Way Test
ANOVA <- lm(ConfirmedLOG ~ NavajoR, data=covidtest3)
Anova(ANOVA, Type="II", white.adjust=TRUE)
## Post-Hoc
## Bonferroni Adj
pairwise.t.test(covidtest3$ConfirmedLOG, covidtest3$NavajoR,
p.adjust="bonferroni", pool.sd = FALSE)
# Normality
plotNormalHistogram(covidtest3$Deaths)
covidtest3$DeathsLOG <- log(covidtest3$Deaths)
covidtest4 <-NaRV.omit(covidtest3)
=======
# Normality
plotNormalHistogram(covidtest3$Deaths)
covidtest3$DeathsLOG <- log(covidtest3$Deaths)
>>>>>>> master
# Drop NAs
covidtest4 <-NaRV.omit(covidtest3)
# Homogeneity of Variance
bartlett.test(covidtest4$DeathsLOG ~ NavajoR, data= covidtest4)
## Welch's One-Way Test
ANOVA2 <- lm(DeathsLOG ~ NavajoR, data=covidtest4)
Anova(ANOVA2, Type="II", white.adjust=TRUE)
<<<<<<< HEAD
=======
# Bonferroni Adj
pairwise.t.test(covidtest4$DeathsLOG, covidtest4$NavajoR, p.adjust="bonferroni", pool.sd = FALSE)
# Means & Conclusions
DeathsMeans <- covidtest4 %>% group_by(NavajoR) %>%
summarize(Mean = mean(Deaths))
>>>>>>> master
# Normality
plotNormalHistogram(covidtest3$Incident_Rate)
# Homogeneity of Variance
bartlett.test(Incident_Rate ~ NavajoR, data= covidtest3)
<<<<<<< HEAD
# Normality
plotNormalHistogram(covidtest3$Incident_Rate)
# Normal dist.
# Homogeneity of Variance
bartlett.test(Incident_Rate ~ NavajoR, data= covidtest3)
# p value > .05, homogeneity met
# ANOVA
IncidentANOVA <- aov(covidtest3$Incident_Rate ~ covidtest3$NavajoR)
# Normality
plotNormalHistogram(covidtest3$Incident_Rate)
# Normal dist.
# Homogeneity of Variance
bartlett.test(Incident_Rate ~ NavajoR, data= covidtest3)
# ANOVA
IncidentANOVA <- aov(covidtest3$Incident_Rate ~ covidtest3$NavajoR)
summary(IncidentANOVA)
### ANOVAs for CASE_FATALITY_RATIO
# Normality
=======
# ANOVA
IncidentANOVA <- aov(covidtest3$Incident_Rate ~ covidtest3$NavajoR)
## Post-Hoc
pairwise.t.test(covidtest3$Incident_Rate, covidtest3$NavajoR, p.adjust="bonferroni")
## Means & Conclusions
IncidentMeans <- covidtest3 %>% group_by(NavajoR) %>% summarize(Mean = mean(Incident_Rate))
>>>>>>> master
plotNormalHistogram(covidtest3$Case_Fatality_Ratio)
covidtest4$RatioLOG <- log(covidtest4$Case_Fatality_Ratio)
plotNormalHistogram(covidtest4$RatioLOG)
# Homogeneity of Variance
bartlett.test(RatioLOG ~ NavajoR, data= covidtest4)
<<<<<<< HEAD
RatioANOVA <- aov(covidtest4$RatioLOG ~ covidtest4$NavajoR)
RatioANOVA <- aov(covidtest4$RatioLOG ~ covidtest4$NavajoR)
summary(RatioANOVA)
=======
# ANOVA
RatioANOVA <- aov(covidtest4$RatioLOG ~ covidtest4$NavajoR)
summary(RatioANOVA)
# ANOVA
RatioANOVA <- aov(covidtest4$RatioLOG ~ covidtest4$NavajoR)
>>>>>>> master
summary(RatioANOVA)
# Post-Hoc
pairwise.t.test(covidtest4$RatioLOG, covidtest4$NavajoR, p.adjust="bonferroni")
